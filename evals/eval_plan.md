# ðŸ“ Evalueringsplan â€“ Deep Research Agent

## ðŸŽ¯ MÃ¥l
Verifisere at genererte rapporter og resultater fra agentene oppfyller krav til:
- **Kildekvalitet** (trovÃ¦rdige, transparente og etterprÃ¸vbare kilder).  
- **Konsistens** (sammenhengende og logisk struktur i rapporter).  
- **Handlingsbarhet** (resultatene kan brukes til beslutning eller videre analyse).  

---

## ðŸ› ï¸ Metoder

### 1. Sjekkliste (manuell)
- âœ… Er alle kilder oppgitt med URL / DOI / referanse?  
- âœ… Er rapporten strukturert (intro, hoveddel, konklusjon, referanser)?  
- âœ… Er argumentasjonen logisk uten selvmotsigelser?  
- âœ… Er eventuelle anbefalinger tydelige og realistiske?  
- âœ… Er sprÃ¥k og tone profesjonell og forstÃ¥elig?  

### 2. Automatisert evaluering (pytest + scripts)
- [ ] Test for minimum antall kilder (> 3).  
- [ ] Test at alle referanser har gyldig URL-format.  
- [ ] Test at Markdown validerer uten feil.  
- [ ] Test at nÃ¸kkelord/tema faktisk finnes i rapporten.  
- [ ] Test at rapporten ikke inneholder tomme seksjoner.  

### 3. Kvalitative kriterier (peer review)
- Review av minst Ã©n annen utvikler/forsker.  
- Tilbakemelding logges i GitHub Issues / Project board.  

---

## ðŸ“Š Output
- Evalueringsrapport (Markdown eller PDF) per leveranse.  
- Testresultater fra `pytest` lagres som artefakter i CI/CD.  
- Oppsummering per sprint i GitHub Project board.

---

## ðŸ”„ Integrasjon i arbeidsflyt
- **Pre-commit hooks**: sjekker enkel syntaks, URL-format og filstruktur.  
- **CI/CD (GitHub Actions / Cloud Build)**: kjÃ¸rer pytest-baserte evalueringstester.  
- **Review-prosess**: obligatorisk code review og eval-plan sjekkliste.  

---

| Eier | Sist oppdatert | Godkjent av | Status | Kontakt |
|---|---|---|---|---|  
| NORSAIN / Henrik Strand | 2025-08-17 | â€“ | Utkast | info@norsain.com |
